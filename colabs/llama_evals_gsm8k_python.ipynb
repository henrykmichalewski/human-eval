{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "toc_visible": true,
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/henrykmichalewski/human-eval/blob/master/LLama_evals_gsm8k_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/henrykmichalewski/human-eval\n",
        "!pip install -e human-eval -q"
      ],
      "metadata": {
        "id": "8XfB110qFyL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The above cell clones the unlocked variant of the OpenAI HumanEval repo.\n",
        "\n",
        "Unlocking means that the correctness code is actually executing completions. The repo contains some helper code to simplify gsm8k_python evaluations. You need to reset the runtime before moving forward."
      ],
      "metadata": {
        "id": "XUI6RP5buCGg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading gsm8k"
      ],
      "metadata": {
        "id": "jJH11qRe9Ax5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q"
      ],
      "metadata": {
        "id": "PCe3l7wJu6ZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "9hfa5K9X8r0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gsm8k = load_dataset(\"gsm8k\", \"main\")"
      ],
      "metadata": {
        "id": "DD07jtLW8xi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gsm8k_train, gsm8k_test = gsm8k['train'], gsm8k['test']"
      ],
      "metadata": {
        "id": "QhpOyI1Q81K3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from human_eval.execution import check_gsm8k_correctness"
      ],
      "metadata": {
        "id": "CcGTboYNF2yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_gsm8k_correctness(gsm8k_test[5], \" return 63\", task_id=5)"
      ],
      "metadata": {
        "id": "AclQ1Z7jGP08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_gsm8k_correctness(gsm8k_test[5], \" return 64\", task_id=5)"
      ],
      "metadata": {
        "id": "x8221tb_GcKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_gsm8k_correctness(gsm8k_test[5], \" return 64.000001\", task_id=5)"
      ],
      "metadata": {
        "id": "EYsJAZ2DKXCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install standard HuggingFace dependencies"
      ],
      "metadata": {
        "id": "xbMqVsX0uZOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@main accelerate"
      ],
      "metadata": {
        "id": "hhaIAVIZwrxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece -q"
      ],
      "metadata": {
        "id": "z-r7EULUxXtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "hQes5abu-MSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "qaDj9jr1_L7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "rFk_YMdk_uM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the model"
      ],
      "metadata": {
        "id": "e_f10axCu448"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, TextStreamer, LlamaTokenizer, LlamaForCausalLM\n",
        "\n",
        "# model_name = \"codellama/CodeLlama-7b-Python-hf\" - also a strong competitor\n",
        "model_name = \"codellama/CodeLlama-13b-Python-hf\"\n",
        "\n",
        "tok = LlamaTokenizer.from_pretrained(model_name)\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    model_name, torch_dtype=torch.float16, device_map='auto',\n",
        ")\n",
        "inputs = tok([\"An increasing sequence: one,\"], return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "b2jTumjg5Arb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "QdAHa7a4A5Ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.to(model.device)\n",
        "streamer = TextStreamer(tok)\n",
        "\n",
        "output = model.generate(**inputs, streamer=streamer, max_new_tokens=20)"
      ],
      "metadata": {
        "id": "mk7oE0gNAx33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "UYgrklf34eZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tok.batch_decode(output, skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "7Gqoi_ns5xYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_one_completion(prompt):\n",
        "    # Convert prompt to tensors\n",
        "    inputs = tok([prompt], return_tensors=\"pt\")\n",
        "\n",
        "    # Move tensors to the same device as the model\n",
        "    inputs = inputs.to(model.device)\n",
        "\n",
        "    # Generate output using the model\n",
        "    output = model.generate(**inputs, max_new_tokens=256)\n",
        "\n",
        "    # Decode the output and skip any special tokens\n",
        "    return tok.batch_decode(output, skip_special_tokens=True)[0]"
      ],
      "metadata": {
        "id": "YLkB7F8f56nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_one_completion(f\"Hey there {model_name}!\")"
      ],
      "metadata": {
        "id": "PpAaxs5M6WNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading/Saving samples into gdrive"
      ],
      "metadata": {
        "id": "mHc56CE10RUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "metadata": {
        "id": "482up10cQ_cL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = f'/content/gdrive/My Drive/llama/{model_name}'\n",
        "os.makedirs(path, exist_ok=True)\n",
        "from human_eval.data import stream_jsonl, write_jsonl"
      ],
      "metadata": {
        "id": "tk2YisgJTSkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read jsonl"
      ],
      "metadata": {
        "id": "EGGFns126jYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  samples = list(stream_jsonl(os.path.join(path, \"samples_gsm8k.jsonl\")))\n",
        "except:\n",
        "  samples = []"
      ],
      "metadata": {
        "id": "8aBRab2o2qlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(samples)"
      ],
      "metadata": {
        "id": "EbCVJ76Fb4AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full loop"
      ],
      "metadata": {
        "id": "sWbKV3tC7pN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from data import gsm8k_python_prompt"
      ],
      "metadata": {
        "id": "rUsu9zF7vlPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "all_correct = 0\n",
        "for task_id, problem in enumerate(gsm8k_test):\n",
        "\n",
        "    # Check if task_id is less than samples length\n",
        "    if task_id < len(samples):\n",
        "        correctness = check_gsm8k_correctness(problem, samples[task_id]['completion'], task_id=task_id)\n",
        "        correct = correctness['passed']\n",
        "        all_correct += correct\n",
        "        continue\n",
        "\n",
        "    # Print Task ID\n",
        "    print(f\"task_id {task_id}\")\n",
        "\n",
        "    # Formulate and print the full prompt\n",
        "    full_prompt = (gsm8k_python_prompt.PYTHON_PROMPT + '\\n' +\n",
        "                  gsm8k_python_prompt.PYTHON_TEMPLATE.format(question=problem['question']))\n",
        "    completion = generate_one_completion(full_prompt)\n",
        "    completion = completion[len(full_prompt):].split('\\n\\n')[0]\n",
        "    print(completion)\n",
        "\n",
        "    # New lines for visibility\n",
        "    print(\"\\n\")\n",
        "    print(problem['answer'])\n",
        "\n",
        "    # Check for correctness of the problem solved\n",
        "    correctness = check_gsm8k_correctness(problem, completion, task_id=task_id)\n",
        "    correct = correctness['passed']\n",
        "    all_correct += correct\n",
        "\n",
        "    # Print out the correctness\n",
        "    print(f\"Correctnes: {correct}\\nAll correct: {all_correct}\")\n",
        "    print(\"=\"*40)\n",
        "\n",
        "    # Append the task results to the list and check if need to write to JSON file\n",
        "    samples.append(dict(task_id=task_id, completion=completion))\n",
        "    if task_id % 100 == 0 and task_id:\n",
        "        write_jsonl(os.path.join(path, \"samples_gsm8k.jsonl\"), samples)\n",
        "\n",
        "# Write all samples to JSONL file at the end\n",
        "write_jsonl(os.path.join(path, \"samples_gsm8k.jsonl\"), samples)\n"
      ],
      "metadata": {
        "id": "4SnHfNaq5pyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write jsonl"
      ],
      "metadata": {
        "id": "ILUoZmKp6nAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "write_jsonl(os.path.join(path, \"samples_gsm8k.jsonl\"), samples)"
      ],
      "metadata": {
        "id": "lA6qRPr6TQGC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}